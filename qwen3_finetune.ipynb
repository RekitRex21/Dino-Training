{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# Fine-tune Qwen3:8b for Dino Assistant"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install dependencies\n!pip install -q transformers accelerate peft datasets"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json, os\nfrom google.colab import userdata\n\n# Clone training data\n!git clone https://github.com/RekitRex21/Dino-Training.git\nos.chdir('Dino-Training')"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load and combine training data\ndata = []\n\n# Load JSON files\nfor f in ['security_analysis.json', 'trading.json']:\n    with open(f) as fp:\n        data.extend(json.load(fp))\n\n# Load JSONL\nwith open('rex_assistant.jsonl') as fp:\n    for line in fp:\n        data.append(json.loads(line))\n\nprint(f\"Loaded {len(data)} training examples\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Format for training\nformatted_data = []\nfor item in data:\n    text = f\"Instruction: {item['instruction']}\\n\\nInput: {item.get('input', '')}\\n\\nOutput: {item['output']}\"\n    formatted_data.append({'text': text})\n\nprint(f\"Formatted {len(formatted_data)} examples\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load tokenizer - USE QWEN\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\", trust_remote_code=True)\nprint(\"Tokenizer loaded\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Tokenize\ndef tokenize(sample):\n    return tokenizer(sample['text'], truncation=True, max_length=2048)\n\nfrom datasets import Dataset\nds = Dataset.from_list(formatted_data)\nds = ds.map(tokenize, batched=True)\nprint(f\"Tokenized dataset: {len(ds)} examples\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load model with 4-bit quantization\nimport torch\nfrom transformers import AutoModelForCausalLM, BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"Qwen/Qwen2-7B-Instruct\",\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\nprint(\"Model loaded!\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Setup LoRA\nfrom peft import LoraConfig, get_peft_model\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train!\nfrom transformers import Trainer, TrainingArguments\n\nargs = TrainingArguments(\n    output_dir=\"./qwen3-dino\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    logging_steps=10,\n    save_steps=50,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=ds,\n)\n\ntrainer.train()"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save model\nmodel.save_pretrained(\"./qwen3-dino-final\")\ntokenizer.save_pretrained(\"./qwen3-dino-final\")\nprint(\"Model saved!\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Download for local use\n!zip -r qwen3-dino-model.zip qwen3-dino-final/\nprint(\"Zipped! Right-click to download.\")"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
